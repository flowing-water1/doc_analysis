import json

import pandas as pd
import streamlit as st
import os
from utils import dataframe_agent, analysis_agent, word_similarity_agent
from docx import Document

os.environ["http_proxy"] = f"http://127.0.0.1:7890"
os.environ["https_proxy"] = f"http://127.0.0.1:7890"


def create_chart(input_data, chart_type):
    df_data = pd.DataFrame(input_data["data"], columns=input_data["columns"])
    df_data.set_index(input_data["columns"][0], inplace=True)
    if chart_type == "bar":
        st.bar_chart(df_data)
    elif chart_type == "line":
        st.line_chart(df_data)
    elif chart_type == "scatter":
        st.scatter_chart(df_data)


st.title("ğŸ’¡ æ•°æ®åˆ†ææ™ºèƒ½å·¥å…·")

with st.sidebar:
    openai_api_key = st.text_input("è¯·è¾“å…¥OpenAI APIå¯†é’¥ï¼š", type="password")
    openai_api_base = st.text_input("è¯·è¾“å…¥API_BASEï¼š")
    st.markdown("[è·å–OpenAI API key](https://platform.openai.com/account/api-keys)")


data = st.file_uploader("ä¸Šä¼ ä½ çš„æ•°æ®æ–‡ä»¶ï¼ˆxlsxæˆ–csvæ ¼å¼ï¼‰ï¼š", type=['xlsx', 'csv'])
if data:
    # è·å–æ–‡ä»¶æ‰©å±•å
    file_extension = data.name.split('.')[-1]

    # æ ¹æ®æ‰©å±•åé€‰æ‹©è¯»å–æ–¹å¼
    if file_extension == 'xlsx':
        st.session_state["df"] = pd.read_excel(data)
    elif file_extension == 'csv':
        st.session_state["df"] = pd.read_csv(data)
    else:
        st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ xlsxæˆ–csvæ–‡ä»¶ã€‚")

    with st.expander("åŸå§‹æ•°æ®"):
        st.dataframe(st.session_state["df"])

import streamlit as st
from docx import Document



query = st.text_area("è¯·è¾“å…¥ä½ å…³äºä»¥ä¸Šè¡¨æ ¼çš„é—®é¢˜ï¼Œæˆ–æ•°æ®æå–è¯·æ±‚ï¼Œæˆ–å¯è§†åŒ–è¦æ±‚ï¼ˆæ”¯æŒæ•£ç‚¹å›¾ã€æŠ˜çº¿å›¾ã€æ¡å½¢å›¾ï¼‰ï¼š")
button = st.button("ç”Ÿæˆå›ç­”", key="1")

st.divider()

st.title("ğŸ“ˆè¡¨æ ¼æ•°æ®åˆ†æ")
if "df" not in st.session_state:
    st.info("ç›´æ¥åœ¨ä¸Šé¢é‚£é‡Œä¼ å…¥å³å¯")
else:
    with st.expander("åŸå§‹æ•°æ®"):
        st.dataframe(st.session_state["df"])
analysis_button = st.button("åˆ†ææ•°æ®", key="2")

st.divider()

st.title("ğŸ“„ Wordæ–‡ä»¶ç›¸ä¼¼åº¦æ¯”å¯¹")
# åˆ›å»ºä¸¤åˆ—
col1, col2 = st.columns(2)

# ç¬¬ä¸€åˆ—ï¼šå¤„ç†ç¬¬ä¸€ä¸ªWordæ–‡ä»¶
with col1:
    word_data_1 = st.file_uploader("ä¸Šä¼ ä½ çš„æ•°æ®æ–‡ä»¶1ï¼ˆdocxæ ¼å¼ï¼‰ï¼š", type="docx")
    if word_data_1:
        # è¯»å–Wordå†…å®¹
        doc = Document(word_data_1)
        st.session_state["word_content_1"] = "\n".join([para.text for para in doc.paragraphs])

        # åœ¨é¡µé¢æ˜¾ç¤ºWordå†…å®¹
        with st.expander("åŸå§‹æ•°æ®1"):
            st.text(st.session_state["word_content_1"])

# ç¬¬äºŒåˆ—ï¼šå¤„ç†ç¬¬äºŒä¸ªWordæ–‡ä»¶
with col2:
    word_data_2 = st.file_uploader("ä¸Šä¼ ä½ çš„æ•°æ®æ–‡ä»¶2ï¼ˆdocxæ ¼å¼ï¼‰ï¼š", type="docx")
    if word_data_2:
        # è¯»å–Wordå†…å®¹
        doc = Document(word_data_2)
        st.session_state["word_content_2"] = "\n".join([para.text for para in doc.paragraphs])

        # åœ¨é¡µé¢æ˜¾ç¤ºWordå†…å®¹
        with st.expander("åŸå§‹æ•°æ®2"):
            st.text(st.session_state["word_content_2"])
word_button = st.button("æ¯”å¯¹ç›¸ä¼¼åº¦", key="3")

if (button or analysis_button or word_button) and not openai_api_key:
    st.toast("è¯·å…ˆè¾“å…¥OpenAI APIå¯†é’¥", icon="ğŸš¨")

if (button or analysis_button) and "df" not in st.session_state:

    st.toast("è¯·å…ˆä¸Šä¼ excelæ•°æ®æ–‡ä»¶",icon="ğŸš¨")

if word_button and "word_content_1" not in st.session_state and "word_content_2" not in st.session_state:
    st.toast("è¯·å…ˆä¸Šä¼ wordæ•°æ®æ–‡ä»¶",icon="ğŸš¨")


if button and openai_api_key and "df" in st.session_state:
    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
        response, read = dataframe_agent(openai_api_key, openai_api_base, st.session_state["df"], query)
        st.write(response)
        st.divider()
        st.write("æ€è€ƒè¿‡ç¨‹ï¼š")
        st.json(read, expanded=False)
        st.divider()

        # æ£€æŸ¥ read ä¸­çš„æ¯ä¸ªå…ƒç´ 
        if isinstance(read, list):
            for i, element in enumerate(read):

                if isinstance(element, tuple) and len(element) > 0:
                    log_content = element[0].log if hasattr(element[0], 'log') else None
                    remaining_content = element[1] if len(element) > 1 else None

                    if log_content:
                        st.write(f"æ€è€ƒè¿‡ç¨‹{i + 1}ï¼š")
                        st.write(log_content)

                    # ç¡®ä¿ remaining_content æ˜¯æœ‰æ•ˆçš„ç±»å‹
                    if remaining_content is not None:
                        # æ£€æŸ¥æ˜¯å¦ä¸º Pandas Index ç±»å‹
                        if isinstance(remaining_content, pd.Index):
                            st.write(remaining_content.tolist())  # è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼å±•ç¤º
                            st.divider()
                        else:
                            st.write(remaining_content)
                            st.divider()
                    else:
                        st.write(f"å…ƒç´  {i} ä¸­æ²¡æœ‰åç»­å†…å®¹ã€‚")
        else:
            st.write("read ä¸æ˜¯æœ‰æ•ˆçš„åˆ—è¡¨æ ¼å¼ã€‚")

        response_dict = json.loads(response)
        if "answer" in response_dict:
            st.write(response_dict["answer"])
        if "table" in response_dict:
            st.table(pd.DataFrame(response_dict["table"]["data"],
                                  columns=response_dict["table"]["columns"]))
        if "bar" in response_dict:
            create_chart(response_dict["bar"], "bar")
        if "line" in response_dict:
            create_chart(response_dict["line"], "line")
        if "scatter" in response_dict:
            create_chart(response_dict["scatter"], "scatter")

if analysis_button and openai_api_key and "df" in st.session_state:
    with st.spinner("AIæ­£åœ¨åˆ†ææ•°æ®ä¸­ï¼Œè¯·ç¨ç­‰..."):
        analysis_result, read = analysis_agent(openai_api_key, openai_api_base, st.session_state["df"])
        st.write(analysis_result)
        st.divider()
        st.write("æ€è€ƒè¿‡ç¨‹ï¼š")
        st.json(read, expanded=False)
        st.divider()
        # æ£€æŸ¥ read ä¸­çš„æ¯ä¸ªå…ƒç´ 
        if isinstance(read, list):
            for i, element in enumerate(read):

                if isinstance(element, tuple) and len(element) > 0:
                    log_content = element[0].log if hasattr(element[0], 'log') else None
                    remaining_content = element[1] if len(element) > 1 else None

                    if log_content:
                        st.write(f"æ€è€ƒè¿‡ç¨‹{i + 1}ï¼š")
                        st.write(log_content)

                    # ç¡®ä¿ remaining_content æ˜¯æœ‰æ•ˆçš„ç±»å‹
                    if remaining_content is not None:
                        # æ£€æŸ¥æ˜¯å¦ä¸º Pandas Index ç±»å‹
                        if isinstance(remaining_content, pd.Index):
                            st.write(remaining_content.tolist())  # è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼å±•ç¤º
                            st.divider()
                        else:
                            st.write(remaining_content)
                            st.divider()
                    else:
                        st.write(f"å…ƒç´  {i} ä¸­æ²¡æœ‰åç»­å†…å®¹ã€‚")
        else:
            st.write("read ä¸æ˜¯æœ‰æ•ˆçš„åˆ—è¡¨æ ¼å¼ã€‚")

if word_button and openai_api_key and word_data_1 and word_data_2:
    with st.spinner("AIæ­£åœ¨åˆ†ææ•°æ®ä¸­ï¼Œè¯·ç¨ç­‰..."):
        word_result= word_similarity_agent(openai_api_key, openai_api_base,
                                                       st.session_state["word_content_1"],
                                                       st.session_state["word_content_2"])

        st.write(word_result)